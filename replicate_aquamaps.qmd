---
title: "Replicate AquaMaps"
description: "Compare replicated AquaMaps species distributions against the original"
execute:
  warning: false
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup

librarian::shelf(
  cmocean, DBI, dplyr, DT, duckdb, fs, glue, here, htmltools, janitor, knitr,
  leaflet, leaflet.extras, leaflet.extras2, librarian, logger, lubridate,
  mapview, ggplot2, listviewer, purrr, scales, marinesensitivity/msens, 
  RColorBrewer, readr, sf, stringr, terra, tibble, tidyr,
  quiet = T)
options(readr.show_col_types = F)
mapviewOptions(basemaps = "Esri.OceanBasemap")

is_server = Sys.info()[["sysname"]] == "Linux"
path_dd   <- ifelse(
  is_server,
  "/share/data/aquamapsduckdb/am.duckdb",
  "~/My Drive/projects/msens/data/derived/aquamaps/am.duckdb")
dir_cache <- here("data/replicate_aquamaps")
dir.create(dir_cache, showWarnings = FALSE, recursive = TRUE)

con_dd    <- dbConnect(
  duckdb(
    dbdir     = path_dd,
    read_only = T))

am_meta_csv <- here("data/aquamaps_meta.csv")
if (!file.exists(am_meta_csv)) {
  tbl(con_dd, "_tbl_fld_renames") |> 
    collect() |> 
    left_join(
      aquamapsdata::am_meta,
      by = join_by(tbl_old == table, fld_old == field)) |> 
    write_csv(am_meta_csv)
}
am_meta <- read_csv(am_meta_csv)

# Load functions from libs/am_functions.R
source(here("libs/am_functions.R"))
```

## Test Functions with a Single Species

```{r}
#| label: test_single_species

# source(here("libs/am_functions.R"))

# Test with a single species
# sp_key <- "W-Msc-419703"  # Crepidula depressa
# sp_key <- "ITS-Mam-180530"
# sp_key <- "Fis-22747" # Cetorhinus maximus bbox inside issue
# sp_key <- "ITS-Mam-180527" # fin whale sorted
# sp_key <- "ITS-Mam-180524" # sorted with tolerance 0.01
# sp_key <- "W-Pol-129784"
sp_key <- "Fis-22747"

# Get species information with enhanced details
sp_info <- get_sp_info(sp_key)
jsonedit(sp_info)

# Get original raster
r_sp_old <- get_species_raster(sp_key, con_dd, dir_cache = dir_cache)

# Replicate raster using enhanced species info
r_sp_new <- replicate_sp_raster(sp_key, con_dd, dir_cache = dir_cache, redo = T)

ext(r_sp_old)
ext(r_sp_new)

# Compare rasters
matches <- compare_rasters(r_sp_old, r_sp_new)
cat(glue("Rasters match: {matches}\n"))

if (!matches) {
  # Get difference raster
  r_dif <- compare_rasters(r_sp_old, r_sp_new, return = "rast")
  plet(r_dif)
  
  # Get detailed comparison data
  d_cmp <- compare_rasters(r_sp_old, r_sp_new, return = "tibble", sp_key = sp_key, con_dd = con_dd)
  
  # # Examine specific cell differences
  # x <- d_cmp |>
  #   filter(dif_abs > 0.02) |>
  #   slice(1:10)
  # View(x)
}

# Visual comparison
compare_sp(r_sp_old, r_sp_new, sp_key)

# Interactive diagnostic visualization
create_diagnostic_visual(sp_key, con_dd)
```

## Create Diagnostic Table

```{r}
#| label: create_diagnostic_table

# Select a small sample of species for testing
sample_sp_keys <- c(
  "Fis-22747",   # Cetorhinus maximus (bbox hole issue)
  "ITS-Mam-180527", # Fin whale
  "W-Pol-129784",
  "ITS-Mam-180524",
  "W-Msc-419703")  # Crepidula depressa

# source(here("libs/am_functions.R"))
# Create diagnostic table
diag_table <- create_diagnostic_table(sample_sp_keys, con_dd)

# Display the diagnostic table
diag_table |>
  DT::datatable(
    caption = "AquaMaps Species Diagnostic Comparison",
    options = list(scrollX = TRUE))

# Save diagnostic table
write_csv(diag_table, here("data/aquamaps_diagnostic_table.csv"))
```

## Validate Multiple Species

```{r}
#| label: validate_multiple_species

ply_br_a_geo     <- glue("{dir_cache}/ply_boemrgns_antimeridian.geojson")
ply_cells_br_geo <- glue("{dir_cache}/ply_cells_boemrgns.geojson")
spp_br_csv       <- glue("{dir_cache}/spp_boemrgns.csv")
do_map_br        <- F

# get regions, breaking on antimeridan
if (!file.exists(ply_br_a_geo)) {
  sf_use_s2(F)
  ply_br_a <- msens::ply_boemrgns |> 
    st_break_antimeridian()
  sf_use_s2(T)
  
  write_sf(
    ply_br_a, 
    ply_br_a_geo, 
    delete_dsn = T)
}
ply_br_a <- read_sf(ply_br_a_geo)

# get cells in regions
if (!file.exists(ply_cells_br_geo)) {
  # get cells in regions
  pts_cells <- tbl(con_dd, "cells") |> 
  select(cell_id, center_long, center_lat) |> 
  collect() |> 
  st_as_sf(
    coords = c("center_long", "center_lat"), crs = 4326)

  # create template raster from global dimensions and resolution
  r_g <- rast(
    xmin = -180, xmax = 180, 
    ymin = -90,  ymax = 90, 
    resolution = 0.5)
  
  # rasterize based on cell_id
  r_cells <- rasterize(pts_cells, r_g, field = "cell_id", fun = "last")
  names(r_cells) <- "cell_id"
  
  # convert to polygons
  ply_cells <- as.polygons(r_cells) |> 
    st_as_sf() |> 
    st_set_crs(4326) |> 
    st_cast("POLYGON")
  
  # identify boem regions per cell
  ply_cells_br <- ply_cells |> 
    st_filter(ply_br_a, .predicate = st_intersects)
  
  write_sf(
    ply_cells_br, 
    ply_cells_br_geo, 
    delete_dsn = T)
}
ply_cells_br <- read_sf(ply_cells_br_geo) |> 
  mutate(one = "one") |> 
  relocate(one)

if (do_map_br)
  mapView(ply_br_a, col.regions = "red", alpha = 0.5) +
    mapView(ply_cells_br, col.regions = "blue", alpha = 0.5)

if (!file.exists(spp_br_csv)) {
  # get species in boem regions with number of cells
  d_spp_br <- tbl(con_dd, "spp_cells") |> 
    filter(cell_id %in% ply_cells_br$cell_id) |>
    group_by(sp_key) |>
    summarize(n_cells_br = n()) |> 
    collect() |> 
    arrange(sp_key)

  write_csv(
    d_spp_br, 
    spp_br_csv)
}
d_sp_br  <- read_csv(spp_br_csv)

# Validate species with n_cells > 1 in USA BOEM Regions and not already replicated
sp_keys <- d_sp_br |> 
  filter(n_cells_br > 1) |> # 648 / 10,575 species have n_cells_br == 1
  arrange(desc(n_cells_br), sp_key) |>
  mutate(
    sp_repl_tif        = here(glue("data/replicate_aquamaps/replicated/{sp_key}.tif")),
    sp_repl_tif_exists = file.exists(sp_repl_tif)) |>  # 9,927
  # filter(!sp_repl_tif_exists) |> 
  pull(sp_key)

# Validate species
results <- validate_aquamaps_species(sp_keys, con_dd, dir_cache = dir_cache, verbosity = 0, redo = F)
# INFO [2025-05-20 10:31:10] 0001 of 5777: SLB-74929...
# INFO [2025-05-20 10:31:35] 0008 of 5777: W-Msc-419475...
# INFO [2025-05-20 17:42:27] 5777 of 5777: W-Por-171171...

# Save results to CSV
results_csv <- here("data/aquamaps_validation_results.csv")
write_csv(results, results_csv)

# Display summary
cat(glue("Total species processed: {nrow(results)}\n"))                                 # 9,927
cat(glue("Species with matching rasters: {sum(results$r_matches, na.rm=TRUE)}\n"))      # 1,227 or 12.3%
cat(glue("Species with non-matching rasters: {sum(!results$r_matches, na.rm=TRUE)}\n")) # 8,700
cat(glue("Species with errors: {sum(is.na(results$r_matches))}\n"))                     #     0

# Show results table
results |>
  DT::datatable(
    caption = "AquaMaps Validation Results",
    options = list(pageLength = 25))
```

## Create Full Diagnostic Table

```{r}
#| label: create_full_diagnostic
#| eval: false

# Create a full diagnostic table for non-matching species
# This can be time-consuming, so we'll focus on just the non-matching species
nonmatching_sp_keys <- results |> 
  filter(!r_matches) |> 
  pull(sp_key)

# If there are too many, sample a subset
if (length(nonmatching_sp_keys) > 20) {
  set.seed(456)
  nonmatching_sp_keys <- sample(nonmatching_sp_keys, 20)
}

# Create diagnostic table for non-matching species
full_diag_table <- create_diagnostic_table(nonmatching_sp_keys, con_dd)

# Save to CSV
write_csv(full_diag_table, here("data/aquamaps_full_diagnostic.csv"))

# Display
full_diag_table |>
  DT::datatable(
    caption = "Full Diagnostic for Non-matching Species",
    options = list(scrollX = TRUE))

# Analyze patterns
full_diag_table |>
  group_by(is_bbox_hole, sp_class, is_surface) |>
  summarize(count = n(), .groups = "drop") |>
  arrange(desc(count)) |>
  DT::datatable(caption = "Patterns in Non-matching Species")
```

## Analyze Results

```{r}
#| label: analyze_results

# Load results if previously saved
if (file.exists(here("data/aquamaps_validation_results.csv"))) {
  results <- read_csv(here("data/aquamaps_validation_results.csv"))
}

# Get details about species that don't match
if (sum(!results$r_matches, na.rm=TRUE) > 0) {
  non_matching_sp <- results |>
    filter(!r_matches) |>
    pull(sp_key)
  
  # Get species information
  non_matching_info <- tbl(con_dd, "spp") |>
      filter(sp_key %in% non_matching_sp) |>
      collect() |>
      left_join(
        tbl(con_dd, "spp_prefs") |>
          filter(sp_key %in% non_matching_sp) |>
          select(sp_key, pelagic, map_opt, layer) |>
          collect(),
        by = "sp_key")
  
  # Analyze patterns in non-matching species
  non_matching_info |>
    group_by(class) |>
    summarize(count = n(), .groups = "drop") |>
    arrange(desc(count)) |>
    DT::datatable(caption = "Non-matching species by class")
  
  non_matching_info |>
    group_by(pelagic) |>
    summarize(count = n(), .groups = "drop") |>
    DT::datatable(caption = "Non-matching species by pelagic status")
  
  non_matching_info |>
    group_by(map_opt) |>
    summarize(count = n(), .groups = "drop") |>
    DT::datatable(caption = "Non-matching species by map option")
  
  non_matching_info |>
    group_by(layer) |>
    summarize(count = n(), .groups = "drop") |>
    DT::datatable(caption = "Non-matching species by layer (s=surface, b=bottom)")
  
  # Examine a sample of non-matching species in detail
  sample_sp <- sample(non_matching_sp, min(5, length(non_matching_sp)))
  
  for (sp in sample_sp) {
    # Get original and replicated rasters
    r_old <- get_species_raster(sp, con_dd, dir_cache = dir_cache)
    r_new <- replicate_sp_raster(sp, con_dd, dir_cache = dir_cache)
    
    # Create comparison map
    cat(glue("\nExample non-matching species: {sp}\n"))
    compare_sp(r_old, r_new, sp)
    
    # Create diagnostic visualization
    create_diagnostic_visual(sp, con_dd)
  }
}
```

## Get Bio-Oracle v3 higher resolution data

-   [Bio-ORACLE : Marine data layers for ecological modelling](https://www.bio-oracle.org/documentation.php)
-   [Bio-ORACLE : Marine data layers for ecological modelling](https://www.bio-oracle.org/downloads-to-email.php)
-   [bio-oracle/biooracler: R package to access Bio-Oracle data via ERDDAP](https://github.com/bio-oracle/biooracler)
-   [ERDDAP - List of All Datasets](https://erddap.bio-oracle.org/erddap/info/index.html?page=1&itemsPerPage=1000)
-   [Copernicus Marine Data Store \| Copernicus Marine Service](https://data.marine.copernicus.eu/products)

```{r}
#| label: am-meta_bio-oracle_layers
#| eval: false

librarian::shelf(
  bio-oracle/biooracler, janitor, terra, fs,
  quiet = T)

# biooracler:::erddap.bio_oracle.org()
# http://erddap.bio-oracle.org/erddap/
am_meta_lyrs_csv <- here("data/aquamaps_meta_layers.csv")
bo_ds_csv        <- here("data/bio-oracle_datasets.csv")
bo_ds_rel_csv    <- here("data/bio-oracle_datasets_relevant.csv")
bo_ds_vars_csv   <- here("data/bio-oracle_dataset_variables.csv")

# Create a list of AquaMaps environmental layers for reference
env_lyrs <- c(
  "depth_mean", 
  "depth_min",
  "depth_max",
  "sst_an_mean",
  "sbt_an_mean",
  "salinity_mean",
  "salinity_b_mean",
  "oxy_b_mean",
  "prim_prod_mean",
  "ice_con_ann",
  "land_dist")

# Create and save metadata crosswalk table if it doesn't exist
if (!file.exists(am_meta_lyrs_csv)) {
  am_meta |> 
    filter(
      tbl_new == "cells",
      fld_new %in% env_lyrs) |> 
    write_csv(am_meta_lyrs_csv)
}
am_meta_lyrs <- read_csv(am_meta_lyrs_csv)

if (!all(file.exists(bo_ds_csv, bo_ds_vars_csv))) {
  d_ds <- biooracler::list_layers(simplify = T)
  
  d_other <- tribble(
    ~dataset_id, ~category, ~scenario, ~year_min, ~year_max, ~depth,
    "kdpar_mean_baseline_2000_2020_depthsurf", "kdpar_mean", "baseline", 2000, 2020, "depthsurf",
    "par_mean_baseline_2000_2020_depthsurf"  , "par_mean"  , "baseline", 2000, 2020, "depthsurf",
    "terrain_characteristics", "terrain_characteristics", NA, NA, NA, NA)
  
  d_ds <- d_ds |>
    filter(!dataset_id %in% d_other$dataset_id) |>
    separate_wider_delim(
      dataset_id, 
      delim = "_",
      names = c("category", "scenario", "year_min", "year_max", "depth"),
      cols_remove = F) |> 
    mutate(
      year_min = as.integer(year_min),
      year_max = as.integer(year_max) ) |> 
    bind_rows(
      d_other) |> 
    relocate(dataset_id)
  
  # table(d_ds$category)
  #    chl                     clt                     dfe              kdpar_mean 
  #     10                       7                      28                       1 
  # mlotst                     no3                      o2                par_mean 
  #      7                      28                      28                       1 
  #     ph                    phyc                     po4                      si 
  #     28                      28                      28                      28 
  # siconc                 sithick                      so                     swd 
  #      7                       7                      28                      28 
  #    sws                     tas terrain_characteristics                  thetao 
  #     28                       7                       1                      28
    
  # table(d_ds$scenario)
  # baseline   ssp119   ssp126   ssp245   ssp370   ssp460   ssp585 
  #     55       50       50       50       50       50       50 
  
  # table(d_ds$year_min)
  # 2000 2020 
  #   55  300
  
  # table(d_ds$year_max)
  # 2018 2019 2020 2100 
  #   28   17   10  300
  
  # table(d_ds$depth)
  # depthmax depthmean  depthmin depthsurf 
  #       78        78        78       121

  # d_ds_0 <- d_ds
  # nrow(d_ds) # 356
  d_ds <- d_ds |> 
    mutate(
      d_vars = imap(dataset_id, \(x, i){
        message(glue("{i}: {x}"))
        Sys.sleep(0.1)
        y <- biooracler::info_layer(x)
        tibble(
          variable = y$variables$variable_name) |> 
          mutate(
            d_var = map(variable, \(x) y$alldata[[x]]) ) |> 
          unnest(d_var) } ),
      variables = map_chr(d_vars, \(x) paste(sort(unique(x$variable)), collapse = ", ")) )

  d_ds |> 
    select(-d_vars) |>
    write_csv(bo_ds_csv)
  
  d_ds |> 
    select(-d_vars) |>
    filter(scenario == "baseline") |>
    write_csv(bo_ds_rel_csv)
  
  d_ds_vars <- d_ds |> 
    unnest(d_vars) |> 
    select(dataset_id, variable, attribute_name, value) |> 
    filter(attribute_name != "") |>
    pivot_wider(
      names_from  = attribute_name,
      values_from = value) |>
    clean_names()
  
  d_ds_vars |> 
    write_csv(bo_ds_vars_csv)
}
```

```{r}
#| label: download_bio-oracle

# Directory for BioOracle data
dir_bo <- '~/My Drive/projects/msens/data/raw/bio-oracle.org'
bo_tif <- glue("{dir_bo}/bio-oracle_v3.tif")

dir.create(dir_bo, showWarnings = FALSE, recursive = TRUE)

# Define BioOracle v3 layers needed for AquaMaps replication
bo_layers <- list(
  bathymetry = list(
    dataset_id = "terrain_characteristics",
    variables  = c("bathymetry_mean", "bathymetry_min", "bathymetry_max") ),
  thetao_surf = list(
    dataset_id = "thetao_baseline_2000_2019_depthsurf",
    variables  = c("thetao_mean") ),
  thetao_btm = list(
    dataset_id = "thetao_baseline_2000_2019_depthmax",
    variables  = c("thetao_mean") ),
  so_surf = list(
    dataset_id = "so_baseline_2000_2019_depthsurf",
    variables  = c("so_mean") ),
  so_btm = list(
    dataset_id = "so_baseline_2000_2019_depthmax",
    variables  = c("so_mean") ),
  o2_surf = list(
    dataset_id = "o2_baseline_2000_2018_depthmax",
    variables  = c("o2_mean") ),
  o2_btm = list(
    dataset_id = "o2_baseline_2000_2018_depthmax",
    variables  = c("o2_mean") ),
  phyc_surf = list(
    dataset_id = "phyc_baseline_2000_2020_depthsurf",
    variables  = c("phyc_mean") ),
  siconc_surf = list(
    dataset_id = "siconc_baseline_2000_2020_depthsurf",
    variables  = c("siconc_mean") ) )

# Download all required BioOracle layers
for (layer in names(bo_layers)) { # layer = names(bo_layers)[2]
  lyr <- bo_layers[[layer]]
  r_nc <- glue("{dir_bo}/{layer}.nc")
  
  yr <- ifelse(layer == "bathymetry", 1970, 2010)
  
  # Skip if already downloaded
  if (!file.exists(r_nc)) {
    message(glue("Downloading {layer} data to {basename(r_nc)}"))
    r <- biooracler::download_layers(
      dataset_id  = lyr$dataset_id,
      variables   = lyr$variables,
      constraints = list(
        time      = rep(glue("{yr}-01-01T00:00:00Z"), 2),
        longitude = c(-179.975, 179.975),
        latitude  = c(-89.975, 89.975)),
      fmt         = "nc",
      directory   = dirname(r_nc) )
    # Move and rename the downloaded file
    file_move(r$summary$filename, r_nc)
    # Test loading
    r <- rast(r_nc)
    message(glue("Successfully downloaded {layer} with variables: {paste(names(r), collapse=', ')} ({paste(time(r), collapse=', ')})"))
  } else {
    message(glue("{layer} file already exists at {basename(r_nc)}"))
  }
}

# View(d_bo_ds_rel)
d_bo_ds      <- read_csv(bo_ds_csv)
d_bo_ds_vars <- read_csv(
  bo_ds_vars_csv, 
  col_types = cols(
    color_bar_palette = "c"))

# Test loading one of each layer type to verify
r <- rast(
  list.files(dir_bo, "\\.nc$", full.names = TRUE))
d_r <- tibble(
  variable   = names(r),
  # longname   = longnames(r),
  time       = time(r),
  layer      = path_ext_remove(basename(sources(r))),
  dataset_id = map_chr(layer, \(x) bo_layers[[x]]$dataset_id)) |> 
  left_join(
    d_bo_ds,
    by = join_by(dataset_id)) |> 
  left_join(
    d_bo_ds_vars,
    by = join_by(dataset_id, variable)) |> 
  mutate(
    year_min   = year(time),
    depth_str  = case_match(
      depth,
      "depthmax"  ~ " at bottom",
      "depthsurf" ~ " at surface",
      .default    = ""),
    year_str  = if_else(
      !is.na(year_min),
      glue(" for {year_min} to {year_max}"),
      "" ),
    longname  = glue("{long_name}{depth_str}{year_str} ({units}) [{dataset_id}.{variable}.{year_min}]"),
    shortname = if_else(
      layer == "bathymetry",
      variable,
      layer ) ) |> 
  select(
    name = shortname, 
    longname, 
    dataset_id, variable, 
    category, scenario,
    year_min, year_max,
    depth, units,
    ioos_category, standard_name)
# d_r |>
#   # select(shortname, longname) |>
#   View()

names(r) <- d_r$name
for (lyr in names(r)){ # lyr = "so_btm"
  metags(r, layer = lyr) <- d_r |> 
    rename(layer = name) |> 
    filter(layer == lyr) |>
    pivot_longer(
      -layer, 
      names_to  = "name", 
      values_to = "value",
      values_transform = as.character) |>
    select(-layer)
}
# metags(r, layer = "salinity_mean") |> 
#   tibble()
# metags(r) |> 
#   tibble() |> 
#   View()

crs(r) <- "epsg:4326"

lyrs_bo_to_hcaf <- c(
  "bathymetry_mean" = "depth_mean",
  "bathymetry_min"  = "depth_min",
  "bathymetry_max"  = "depth_max",
  "thetao_surf"     = "sst_an_mean",
  "thetao_btm"      = "sbt_an_mean",
  "so_surf"         = "salinity_mean",
  "so_btm"          = "salinity_b_mean",
  "o2_surf"         = "oxy_mean",
  "o2_btm"          = "oxy_b_mean",
  "phyc_surf"       = "prim_prod_mean",
  "siconc_surf"     = "ice_con_ann")
names(r) <- lyrs_bo_to_hcaf[names(r)]

# Convert depth units to positive to match AquaMaps
r <- rast(bo_tif)
for (lyr in names(r)[2:3]){ # lyr = "depth_mean"
  r[[lyr]] <- r[[lyr]] * -1
}
tmp_tif <- tempfile(fileext = ".tif")
writeRaster(r, tmp_tif)
file_delete(bo_tif)
file_move(tmp_tif, bo_tif)

# units(r)
# [1] "m"          "m"          "m"          "MMol' 'M-3" "MMol' 'M-3" "MMol' 'M-3"
#  [7] "1"          "PSU"        "PSU"        "degree_C"   "degree_C"  

file.size(bo_tif) / (1000^3) # 1.3 GB

# plet(r[["bathymetry_mean"]])
# plet(r[["thetao_surf"]])
# # crop to California coast
# r_ca <- crop(r, ext(-130, -120, 30, 40))
# plet(r_ca[["bathymetry_mean"]])
# # crop to SF bay
# r_sf <- crop(r, ext(-123.5, -122.5, 37.5, 38.5))
# plet(r_sf[["bathymetry_mean"]])
```

```{r}
#| label: add_fao_to_bio-oracle_raster

librarian::shelf(
  sf, terra, here,
  quiet = T)
source("libs/am_functions.R")

fao_shp <- "~/My Drive/projects/msens/data/raw/marineregions.org/fao/World_Fao_Zones.shp"

ply_fao <- read_sf(fao_shp) # zone

r_bo <- get_bo_raster()

# rasterize to same topology as BioOracle
r_fao <- rasterize(
  ply_fao, 
  r_bo, 
  field = "zone")
names(r_fao) <- "fao_area_m"

r_bo <- c(r_bo, r_fao)
names(r_bo)

tmp_tif <- tempfile(fileext = ".tif")
writeRaster(r_bo, tmp_tif)
file_delete(bo_tif)
file_move(tmp_tif, bo_tif)

plet(r_fao)


```


```{r}
#| label: add_land-dist_to_bio-oracle_raster

librarian::shelf(
  sf, terra, here,
  quiet = T)
source("libs/am_functions.R")

# r <- get_hcaf_raster()
r <- get_bo_raster()
bo_tif <- sources(r)

r_land <- is.na(r[["depth_mean"]])
# plot(r_land)

system.time({
  r_dist <- distance(
    r_land, target = FALSE, unit = "km", method = "haversine") }) # hcaf: 45.961 sec
# TODO: on server later for more accuracy
system.time({
  r_dist <- distance(
    r_land, target = FALSE, unit = "km", method = "geo") }) # SLOW
# ?terra::distance
# - method: character. One of "geo", "cosine" or "haversine". With "geo" the most precise but slower method of Karney (2003) is used. The other two methods are faster but less precise
# plot(r_dist)

names(r_land) <- "land_dist"

if("land_dist" %in% names(r))
  stop("TODO: land_dist already exists in raster")

r <- c(r, r_land)

tmp_tif <- tempfile(fileext = ".tif")
writeRaster(r, tmp_tif)
file_delete(bo_tif)
file_move(tmp_tif, bo_tif)
```



## Match AquaMaps env to Bio-Oracle layers

```{r}
#| label: match_aquamaps_bio-oracle
#| eval: false

librarian::shelf(
  dplyr, 
  quiet = T)

d_sp_pref |> 
  select(ends_with("_yn")) |> 
  names() |> 
  str_replace("_yn", "")

# "depth"     "temp"      "salinity"  "prim_prod" "ice_con"   "oxy"       "land_dist" "extn_rule"
```

### AquaMaps to Bio-Oracle v3 Layer Mapping

The following table shows the mapping between AquaMaps environmental variables and their Bio-Oracle v3 equivalents:

| AquaMaps Variable | AquaMaps Layer | Bio-Oracle v3 Dataset | Bio-Oracle v3 Variable | Bio-Oracle v3 Layer |
|-------------------|----------------|-----------------------|------------------------|---------------------|
| depth (min)       | depth_min      | terrain_characteristics | bathymetry_min | bathymetry_min |
| depth (mean)      | depth_mean     | terrain_characteristics | bathymetry_mean | bathymetry_mean |
| depth (max)       | depth_max      | terrain_characteristics | bathymetry_max | bathymetry_max |
| temp (surface)    | sst_an_mean    | thetao_baseline_2000-2019_depthsurf | thetao_mean | thetao_surf |
| temp (bottom)     | sbt_an_mean    | thetao_baseline_2000-2019_depthmax | thetao_mean | thetao_max |
| salinity (surface)| salinity_mean  | so_baseline_2000-2019_depthsurf | so_mean | so_surf |
| salinity (bottom) | salinity_b_mean| so_baseline_2000-2019_depthmax | so_mean | so_max |
| oxygen (bottom)   | oxy_b_mean     | o2_baseline_2000-2018_depthmax | o2_mean | o2_max |
| oxygen (surface)  | oxy_mean       | o2_baseline_2000-2018_depthsurf | o2_mean | o2_max |
| primary production| prim_prod_mean | phyc_baseline_2000-2020_depthsurf | phyc_mean | phyc_surf |
| ice concentration | ice_con_ann    | siconc_baseline_2000-2020_depthsurf | siconc_mean | siconc_surf |
| land distance     | land_dist      | (retain HCAF layer - not available in Bio-Oracle) | - | - |

This mapping is implemented in the `replicate_sp_raster()` function, which now accepts an optional `env_layers` parameter that can be set to either "HCAF_v4" (default) or "BioOracle_v3".

### Data Resolution Comparison

- **HCAF**: 1/2 degree (approximately 55 km at the equator)
- **Bio-Oracle v3**: 1/20 degree (approximately 5.5 km at the equator)

The higher resolution of Bio-Oracle v3 allows for more detailed species distribution models, particularly in coastal regions where environmental gradients can change rapidly over short distances.

### Using Bio-Oracle v3 Layers

To use Bio-Oracle v3 layers for replication, call the `replicate_sp_raster()` function with the `env_layers` parameter set to "BioOracle_v3":

```r
# Example using Bio-Oracle v3 layers
r_sp_new <- replicate_sp_raster(
  sp_key = "Fis-22747",
  con_dd = con_dd,
  env_layers = "BioOracle_v3")
```

The function will cache the results with a suffix indicating the data source to differentiate between HCAF and Bio-Oracle based outputs.


```{r}
#| label: test_biooracle_replication
#| eval: false

# Test replication using BioOracle v3 data for a single species
sp_key_test <- "Fis-22747"  # Basking shark (Cetorhinus maximus)

# Get species information
sp_info <- get_sp_info(sp_key_test)

# Get the original raster (HCAF-based)
r_sp_old <- get_species_raster(sp_key_test, con_dd, dir_cache = dir_cache)

# Replicate using BioOracle v3 data
r_sp_new_bo <- replicate_sp_raster(
  sp_key = sp_key_test,
  con_dd = con_dd,
  env_layers = "BioOracle_v3",
  redo = TRUE,
  verbose = TRUE)

# Compare the two distributions visually
compare_sp(
  r_sp_old, 
  r_sp_new_bo, 
  sp_key_test,
  lbl_left = "HCAF (1/2°) →",
  lbl_right = "← BioOracle v3 (1/20°)",
  legend_title = glue::glue("{sp_info$sp_scientific}<br>({sp_key_test})<br>Habitat Suitability"))

# Test with multiple species
test_species <- c(
  "Fis-22747",    # Basking shark (Cetorhinus maximus)
  "ITS-Mam-180527", # Fin whale (Balaenoptera physalus)
  "W-Pol-129784"  # Branchiomma bairdi
)

# Process each species
for (sp_key in test_species) {
  # Get original raster
  r_sp_old <- get_species_raster(sp_key, con_dd, dir_cache = dir_cache)
  
  # Get species info
  sp_info <- get_sp_info(sp_key)
  
  # Replicate with HCAF (default)
  r_sp_new_hcaf <- replicate_sp_raster(
    sp_key = sp_key,
    con_dd = con_dd,
    env_layers = "HCAF_v4",
    redo = TRUE,
    verbose = TRUE)
  
  # Replicate with BioOracle
  r_sp_new_bo <- replicate_sp_raster(
    sp_key = sp_key,
    con_dd = con_dd,
    env_layers = "BioOracle_v3",
    redo = TRUE,
    verbose = TRUE)
  
  # Visual comparison
  cat(glue::glue("\nSpecies: {sp_info$sp_scientific} ({sp_key})\n"))
  
  # Compare original vs HCAF replication
  cat("\nOriginal vs HCAF Replication:\n")
  compare_sp(
    r_sp_old, 
    r_sp_new_hcaf, 
    sp_key,
    lbl_left = "Original →",
    lbl_right = "← HCAF Replication",
    legend_title = glue::glue("{sp_info$sp_scientific}<br>({sp_key})"))
  
  # Compare original vs BioOracle replication
  cat("\nOriginal vs BioOracle Replication:\n")
  compare_sp(
    r_sp_old, 
    r_sp_new_bo, 
    sp_key,
    lbl_left = "Original →",
    lbl_right = "← BioOracle Replication",
    legend_title = glue::glue("{sp_info$sp_scientific}<br>({sp_key})"))
  
  # Compare HCAF vs BioOracle replication
  cat("\nHCAF vs BioOracle Replication:\n")
  compare_sp(
    r_sp_new_hcaf, 
    r_sp_new_bo, 
    sp_key,
    lbl_left = "HCAF (1/2°) →",
    lbl_right = "← BioOracle (1/20°)",
    legend_title = glue::glue("{sp_info$sp_scientific}<br>({sp_key})"))
}
```

```{r}
#| label: batch_biooracle_replication
#| eval: false

# Process a batch of species with both HCAF and BioOracle replication
# and compare performance, accuracy, and differences

# Select a small sample of species for comparison
batch_species <- c(
  "Fis-22747",     # Basking shark (Cetorhinus maximus)
  "ITS-Mam-180527", # Fin whale (Balaenoptera physalus)
  "W-Pol-129784",  # Branchiomma bairdi
  "ITS-Mam-180524", # Blue whale (Balaenoptera musculus)
  "W-Msc-419703"   # Crepidula depressa
)

# Create comparison table
bo_comparison <- tibble::tibble(
  sp_key = character(),
  sp_scientific = character(),
  sp_class = character(),
  hcaf_matches_original = logical(),
  bo_matches_original = logical(),
  hcaf_time_seconds = numeric(),
  bo_time_seconds = numeric(),
  resolution_difference = character()
)

# Get HCAF raster once for efficiency
r_hcaf <- get_hcaf_raster(con_dd)

# Process each species and record metrics
for (sp_key in batch_species) {
  # Get species info
  sp_info <- get_sp_info(sp_key)
  
  # Get original raster
  r_sp_old <- get_species_raster(sp_key, con_dd, r_hcaf, dir_cache = dir_cache)
  
  # Time HCAF replication
  hcaf_start_time <- Sys.time()
  r_sp_hcaf <- replicate_sp_raster(
    sp_key = sp_key,
    con_dd = con_dd,
    r_hcaf = r_hcaf,
    env_layers = "HCAF_v4",
    redo = TRUE)
  hcaf_end_time <- Sys.time()
  hcaf_time <- as.numeric(difftime(hcaf_end_time, hcaf_start_time, units = "secs"))
  
  # Time BioOracle replication
  bo_start_time <- Sys.time()
  r_sp_bo <- replicate_sp_raster(
    sp_key = sp_key,
    con_dd = con_dd,
    r_hcaf = r_hcaf,  # Still needed for FAO areas and land distance
    env_layers = "BioOracle_v3",
    redo = TRUE)
  bo_end_time <- Sys.time()
  bo_time <- as.numeric(difftime(bo_end_time, bo_start_time, units = "secs"))
  
  # Compare results
  hcaf_matches <- compare_rasters(r_sp_old, r_sp_hcaf)
  bo_matches <- compare_rasters(r_sp_old, r_sp_bo, tolerance = 0.20)  # Higher tolerance for different source
  
  # Calculate resolution difference
  hcaf_res <- mean(terra::res(r_sp_hcaf))
  bo_res <- mean(terra::res(r_sp_bo))
  res_diff <- hcaf_res / bo_res
  
  # Add to comparison table
  bo_comparison <- bo_comparison |>
    dplyr::bind_rows(
      tibble::tibble(
        sp_key = sp_key,
        sp_scientific = sp_info$sp_scientific,
        sp_class = sp_info$taxa$class,
        hcaf_matches_original = hcaf_matches,
        bo_matches_original = bo_matches,
        hcaf_time_seconds = hcaf_time,
        bo_time_seconds = bo_time,
        resolution_difference = glue::glue("{round(res_diff, 1)}x finer")
      )
    )
}

# Display comparison results
DT::datatable(
  bo_comparison,
  caption = "Comparison of HCAF vs BioOracle Replication",
  options = list(scrollX = TRUE))

# Save comparison to CSV
write_csv(bo_comparison, here("data/biooracle_comparison.csv"))
```




## Conclusion

This document validates the replication process for AquaMaps species distribution models. It compares the original AquaMaps rasters with our replicated versions to ensure our environmental envelope approach correctly reproduces the original rasters.

The key enhancements from the previous version include:

1. Modular function organization in `libs/am_functions.R`
2. Enhanced species information with actual bounding box and FAO areas
3. Detection of bounding box "holes" where east < west longitude
4. Comprehensive diagnostic table for comparing species properties
5. Interactive diagnostic visualization for examining discrepancies
6. Streamlined performance through caching and optimized functions
7. Integration with Bio-Oracle v3 data for higher resolution (1/20° vs 1/2°) models
8. Support for alternative environmental data sources via the `env_layers` parameter

### BioOracle Integration Benefits

The addition of Bio-Oracle v3 support provides several advantages:

1. **Higher spatial resolution**: Bio-Oracle v3 provides data at 1/20° resolution (approximately 5.5 km at the equator) compared to AquaMaps HCAF's 1/2° resolution (approximately 55 km at the equator). This allows for more detailed species distribution models, especially in coastal areas where environmental gradients change rapidly.

2. **More recent data**: Bio-Oracle v3 includes more recent environmental data (2000-2020) than the original AquaMaps layers, potentially providing more accurate representations of current conditions.

3. **Data source flexibility**: The new implementation allows seamless switching between data sources, facilitating comparisons and sensitivity analyses with different environmental inputs.

4. **Coastal detail**: The higher resolution captures fine-scale coastal features that are particularly important for species with narrow habitat ranges or specific coastal preferences.

### Usage Recommendations

- Use the default HCAF_v4 mode for direct replication of original AquaMaps models
- Use BioOracle_v3 mode for higher resolution models that may better represent species distributions in complex coastal environments
- Consider using both sources and comparing the results to evaluate sensitivity to environmental data resolution and source

The validation report helps identify any discrepancies between the original and replicated models, which can inform further refinements to the replication approach. For BioOracle-based replications, a higher tolerance parameter might be necessary when comparing to original AquaMaps distributions due to the different underlying data sources and resolutions.
